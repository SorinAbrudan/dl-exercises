{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","metadata":{"id":"ZAyjVdm5r_Ra","executionInfo":{"status":"ok","timestamp":1605627726174,"user_tz":-120,"elapsed":2423,"user":{"displayName":"Sorin Abrudan","photoUrl":"","userId":"08478696315690991095"}}},"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"3JSKRFygyStT","executionInfo":{"status":"ok","timestamp":1605627730085,"user_tz":-120,"elapsed":658,"user":{"displayName":"Sorin Abrudan","photoUrl":"","userId":"08478696315690991095"}},"outputId":"428b5fde-aafb-4336-98b6-1ada26dcf0c4","colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["tf.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","metadata":{"id":"rNVogvHHyY0s","executionInfo":{"status":"error","timestamp":1605627732702,"user_tz":-120,"elapsed":543,"user":{"displayName":"Sorin Abrudan","photoUrl":"","userId":"08478696315690991095"}},"outputId":"ec4c15d3-dc81-42f9-89c5-d85ba56bb3ca","colab":{"base_uri":"https://localhost:8080/","height":395}},"source":["train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","\n","training_set = train_datagen.flow_from_directory(\n","        'dataset/training_set',\n","        target_size=(64, 64),\n","        batch_size=32,\n","        class_mode='binary')"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-88669b3c9a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         class_mode='binary')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m   def flow_from_dataframe(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/training_set'"]}]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","metadata":{"id":"WDPCfs7j00ho"},"source":["test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","test_set = test_datagen.flow_from_directory(\n","        'dataset/test_set',\n","        target_size=(64, 64),\n","        batch_size=32,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"code","metadata":{"id":"2cxv_nWsS2bM"},"source":["cnn = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","metadata":{"id":"BFejMNHQS3D1"},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","metadata":{"id":"WGvtNNKwS3nH"},"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","metadata":{"id":"7a0c7xFsVaV0"},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","metadata":{"id":"uEZHML_EVa82"},"source":["cnn.add(tf.keras.layers.Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","metadata":{"id":"NDceRJ0WVbhx"},"source":["cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","metadata":{"id":"8XQnweq5VcID"},"source":["cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","metadata":{"id":"MwBEeXhtZxQi"},"source":["cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","metadata":{"id":"yDRZI5ZbfHb7"},"source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","metadata":{"id":"E70A4UbbfIgg"},"source":["import numpy as np\n","from keras.preprocessing import image\n","\n","test_image = image.load_img('cat_or_dog_1.jpg', targe_size=(64,64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9bG4hH_zXXb"},"source":["print(prediction)"],"execution_count":null,"outputs":[]}]}